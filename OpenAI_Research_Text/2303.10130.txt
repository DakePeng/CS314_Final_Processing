WORKING PAPER GPTs are GPTs: An Early Look at the Labor Market Impact Potential of Large Language Models Tyna Eloundou1, Sam Manning1,2, Pamela Mishkin∗1, and Daniel Rock3 1OpenAI 2OpenResearch 3University of Pennsylvania August 22, 2023 Abstract Weinvestigatethepotentialimplicationsoflargelanguagemodels(LLMs),suchasGenerativePretrainedTransformers(GPTs),ontheU.S.labormarket, focusingontheincreasedcapabilitiesarisingfrom LLM-poweredsoftwarecomparedtoLLMsontheirown. Usinganewrubric,weassessoccupationsbased ontheiralignmentwithLLMcapabilities,integratingbothhumanexpertiseandGPT-4classifications. Ourfindingsrevealthataround80%oftheU.S.workforcecouldhaveatleast10%oftheirworktasks affected by the introduction of LLMs, while approximately 19% of workers may see at least 50% of their tasksimpacted. WedonotmakepredictionsaboutthedevelopmentoradoptiontimelineofsuchLLMs. The projected effects span all wage levels, with higher-income jobs potentially facing greater exposure to LLM capabilities and LLM-powered software. Significantly, these impacts are not restricted to industries withhigherrecentproductivitygrowth. Ouranalysissuggeststhat,withaccesstoanLLM,about15% ofallworkertasksintheUScouldbecompletedsignificantlyfasteratthesamelevelofquality. When incorporating software and tooling built on top of LLMs, this share increases to between 47 and 56% of all tasks. This finding implies that LLM-powered software will have a substantial effect on scaling theeconomicimpactsoftheunderlyingmodels. WeconcludethatLLMssuchasGPTsexhibittraitsof general-purposetechnologies,indicatingthattheycouldhaveconsiderableeconomic,social,andpolicy implications. 1 Introduction AsshowninFigure1,recentyears,months,andweekshaveseenremarkableprogressinthefieldofgenerative AI and large language models (LLMs). While the public often associates LLMs with various iterations of the Generative Pre-trained Transformer (GPT), LLMs can be trained using a range of architectures, and are not limitedto transformer-based models(Devlin etal., 2019). LLMscan processand producevarious formsof sequential data, including assembly language, protein sequences and chess games, extending beyond natural language applications alone. In this paper, we use LLMs and GPTs somewhat interchangeably, and specify in our rubric that these should be considered similar to the GPT-family of models available via ChatGPT or theOpenAI Playground(whichatthe timeoflabeling includedmodelsinthe GPT-3.5familybut notinthe GPT-4family). WeexamineLLMswithtext-andcode-generatingabilities,usetheterm"generativeAI"to additionallyincludemodalitiessuchasimagesoraudio,anduse"LLM-poweredsoftware"tocovertoolsbuilt on top of LLMs or that combine LLMs with other generative AI models. ∗Corresponding author (pamela@openai.com). Authors contributed equally and are listed alphabetically.arXiv:2303.10130v5  [econ.GN]  21 Aug 2023WORKING PAPER Figure 1: Taken directly from GPT-4 Technical Report (OpenAI, 2023b). To get a sense of how quickly modelcapabilitiesareprogressing–considerthejumpinexamperformancebetweenGPT-3.5andGPT-4 (OpenAI, 2023b). Our study is motivated less by the progress of these models alone though, and more by the breadth, scale,andcapabilitieswe’veseeninthecomplementarytechnologiesdevelopedaroundthem. Theroleof complementary technologies remains to be seen, but maximizing the impact of LLMs appears contingent on integrating them with larger systems (Bresnahan, 2019; Agrawal et al., 2021). While the focus of our discussionisprimarilyonthegenerativecapabilitiesofLLMs,itisimportanttonotethatthesemodelscan also be utilized for various tasks beyond text generation. For example, embeddings from LLMs can be used for custom search applications, and LLMs can perform tasks such as summarization and classification where the context may be largely contained in the prompt. To complement predictions of technology’s impacts on work and provide a framework for understanding the evolving landscape of language models and their associated technologies, we propose a new rubric for assessing LLM capabilities and their potential effects on jobs. This rubric (A.1) measures the overall exposureoftaskstoLLMs,followingthespiritofpriorworkonquantifyingexposuretomachinelearning (Brynjolfsson et al., 2018; Felten et al., 2018; Webb, 2020). We define exposure as a proxy for potential economicimpactwithoutdistinguishingbetweenlabor-augmentingorlabor-displacingeffects. Weemploy humanannotatorsandGPT-4itselfasaclassifiertoapplythisrubrictooccupationaldataintheU.S.economy, primarily sourced from the O*NET database. 1 2 Toconstructourprimaryexposuredataset,wecollectedbothhumanannotationsandGPT-4classifications, using a prompt tuned for agreement with a sample of labels from the authors. We observe similar agreement 1ThisisdistinctfromrecentsocialscienceresearchthatmakesuseofLLMstosimulatehumanbehavior(Horton,2023;Sorensen et al., 2022) 2Whileourexposurerubricdoesnotnecessarilytietheconceptoflanguagemodelstoanyparticularmodel,wewerestrongly motivated by our observed capabilities of GPT-4 and the suite of capabilities we saw in development with OpenAI’s launch partners (OpenAI, 2023b).WORKING PAPER levelsinGPT-4responsesandbetweenhumanandmachineevaluations,whenaggregatedtothetasklevel. This exposure measure reflects an estimate of the technical capacity to make human labor more efficient; however, social, economic, regulatory, and other determinants imply that technical feasibility does not guarantee labor productivity or automation outcomes. Our analysis indicates that approximately 19% of jobs haveatleast50%oftheirtasksexposedwhenconsideringbothcurrentmodelcapabilitiesandanticipated tools built upon them. Human assessments suggest that only 3% of U.S. workers have over half of their tasks exposedtoLLMswhenconsideringexistinglanguageandcodecapabilitieswithoutadditionalsoftwareor modalities. Accountingforothergenerativemodelsandcomplementarytechnologies,ourhumanestimates indicate that up to 49% of workers could have half or more of their tasks exposed to LLMs. Our findings consistently show across both human and GPT-4 annotations that most occupations exhibit some degree of exposure to LLMs, with varying exposure levels across different types of work. Occupations withhigherwagesgenerallypresentwithhigherexposure,aresultcontrarytosimilarevaluationsofoverall exposuretomachinelearning(Brynjolfssonetal.,2023). Whenregressingexposuremeasuresonskillsets using O*NET’s skill rubric, we discover that roles heavily reliant on science and critical thinking skills show anegativecorrelationwithexposure,whileprogrammingandwritingskillsarepositivelyassociatedwith LLMexposure. FollowingAutoretal.(2022a),weexaminebarrierstoentryby"JobZones"andfindthat occupational exposure to LLMs weakly increases with the difficulty of job preparation. In other words, workers facing higher (lower) barriers to entry in their jobs tend to experience more (less) exposure to LLMs. Wefurthercompareourmeasurementstopreviouseffortsdocumentingthedistributionofautomation exposureinthe economyandfindbroadlyconsistentresults. Mostothertechnology exposuremeasureswe examine are statistically significantly correlated with our preferred exposure measure, while measures of manualroutinenessandroboticsexposureshownegativecorrelations. Thevarianceexplainedbytheseearlier efforts (Acemogluand Autor, 2011a;Frey and Osborne,2017; Brynjolfsson et al.,2018; Felten etal., 2018; Webb, 2020; Brynjolfsson et al., 2023), along with wage controls, ranges from 60 to 72%, indicating that 28 to40%ofthevariationinourAIexposuremeasureremainsunaccountedforbyprevioustechnologyexposure measurements. Weanalyzeexposurebyindustryanddiscoverthatinformationprocessingindustries(4-digitNAICS) exhibit high exposure, while manufacturing, agriculture, and mining demonstrate lower exposure. The connectionbetweenproductivitygrowthinthepastdecadeandoverallLLMexposureappearsweak,suggesting a potential optimistic case that future productivity gains from LLMs may not exacerbate possible cost disease effects (Baumol, 2012; Aghion et al., 2018). 3 Our analysis indicates that the impacts of LLMs like GPT-4, are likely to be pervasive. While LLMs have consistently improved in capabilities over time, their growing economic effect is expected to persist and increase even if we halt the development of new capabilities today. We also find that the potential impact of LLMs expands significantly when we take into account the development of complementary technologies. Collectively, these characteristics imply that Generative Pre-trained Transformers (GPTs) are general-purpose technologies (GPTs). 4(Bresnahan and Trajtenberg, 1995; Lipsey et al., 2005). (Goldfarb et al., 2023) argue that machine learning as a broad category is likely a general-purpose technology. Ourevidencesupportsawiderimpact,asevensubsetsofmachinelearningsoftwaremeetthe criteriaforgeneral-purposetechnologystatusindependently. Thispaper’sprimarycontributionsaretoprovide asetofmeasurementsofLLMimpactpotentialandtodemonstratetheusecaseofapplyingLLMstodevelop suchmeasurementsefficientlyandatscale. Additionally,weshowcasethegeneral-purposepotentialofLLMs. If "GPTs are GPTs," the eventual trajectory of LLM development and application may be challenging for 3Baumol’s cost disease is a theory that explains why the cost of labor-intensive services, such as healthcare and education, increases over time. This happens because wages for skilled workers in other industries increase, but there is no corresponding increaseinproductivityorefficiencyintheseserviceindustries. Therefore,thecostoflaborintheseindustriesbecomesrelatively more expensive compared to other goods and services in the economy. 4For the remainder of the paper we spell out general-purpose technologies when it is used outside of stating "GPTs are GPTs."WORKING PAPER policymakers to predict and regulate. As with other general-purpose technologies, much of these algorithms’ potential will emerge across a broad range of economically valuable use cases, including the creation of new typesofwork(AcemogluandRestrepo,2018;Autoretal.,2022a). Ourresearchservestomeasurewhatis technically feasible now, but necessarily will miss the evolving impact potential of the LLMs over time. Thepaperisstructuredasfollows: Section2reviewsrelevantpriorwork,Section3discussesmethods and data collection, Section 4 presents summary statistics and results, Section 5 relates our measurements to earlier efforts, Section 6 discusses the results, and Section 7 offers concluding remarks. 2 Literature Review 2.1 The Advancement of Large Language Models Inrecentyears,generativeAImodelshavegainedsignificantattentionfromboththeartificialintelligence (AI) research community and the general public, due to their ability to tackle a wide array of complex language-based tasks. The progress in these models’ abilities has been fueled by multiple factors, including increased model parameter count, greater training data volume, and enhanced training configurations (Brown et al., 2020; Radford et al., 2019; Hernandez et al., 2021; Kaplan et al., 2020). Broad, state-of-the-art LLMs, such as LaMDA (Thoppilan et al., 2022) and GPT-4 (OpenAI, 2023b), excel in diverse applications like translation, classification, creative writing, and code generation—capabilities that previously demanded specialized, task-specific models developed by expert engineers using domain-specific data. Concurrently, researchers have improved the steerability, reliability, and utility of these models using methodslikefine-tuningandreinforcementlearningwithhumanfeedback(Ouyangetal.,2022;Baietal., 2022). These advancements enhance the models’ ability to discern user intent, rendering them more user-friendly and practical. Moreover, recent studies reveal the potential of LLMs to program and control otherdigitaltools,suchasAPIs,searchengines,andevenothergenerativeAIsystems(Schicketal.,2023; Mialon et al., 2023; Chase, 2022). This enables seamless integration of individual components for better utility, performance, and generalization. At their limit, these trends suggest a world where LLMs may be capable of executing any task typically performed at a computer. GenerativeAImodelshavemostlybeendeployedasmodularspecialists,performingspecifictaskssuchas generatingimagesfromcaptionsortranscribingtextfromspeech. However,wearguethatitisessentialtoview LLMs as versatile building blocks for creating additional tools. Developing these tools and integrating them intosystemswillrequiretimeandpossiblysignificantreconfigurationofexistingprocessesacrossvarious industries. Nevertheless, we are already witnessing emerging adoption trends. Despite their limitations, LLMs are increasingly being integrated into specialized applications in fields like writing assistance, coding, and legal research. These specialized applications then allow businesses and individuals to adopt LLMs into their workflows. We emphasize the significance of these complementary technologies, partly because out-of-the-box general-purposeLLMsmaycontinuetobeunreliableforvarioustasksduetoissuessuchasfactualinaccuracies, inherent biases, privacy concerns, and disinformation risks (Abid et al., 2021; Schramowski et al., 2022; Goldsteinetal.,2023;OpenAI,2023a). However,specializedworkflows—includingtooling,software,or human-in-the-loopsystems—canhelpaddresstheseshortcomingsbyincorporatingdomain-specificexpertise. For example, Casetext offers LLM-based legal research tools that provide lawyers with quicker and more accurate legal research results, utilizing embeddings and summarization to counter the risk that GPT-4 could provideinaccuratedetailsaboutalegalcaseorsetofdocuments. GitHubCopilotisacodingassistantthat employsLLMstogeneratecodesnippetsandauto-completecode,whichuserscanthenacceptorrejectbased on their expertise. In other words, while it’s true that on its own GPT-4 does not "know what time it is," it’s easy enough to give it a watch.WORKING PAPER Furthermore,apositivefeedbackloopmayemergeasLLMssurpassaspecificperformancethreshold, allowingthemtoassistinbuildingtheverytoolingthatenhancestheirusefulnessandusabilityacrossvarious contexts. This could lower the cost and engineering expertise required to create such tools, potentially acceleratingLLMadoptionandintegrationevenfurther(Chenetal.,2021;Pengetal.,2023). LLMscanalso becomevaluableassetsinmachinelearningmodeldevelopment—servingascodingassistantsforresearchers, data labeling services, or synthetic data generators. There is potential for such models to contribute to economic decision-making at the task level, for instance, by refining methods for task and sub-task allocation between humans and machines (Singla et al., 2015; Shahaf and Horvitz, 2010). As LLMs advance over time 