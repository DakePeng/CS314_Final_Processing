Computational Limitations in Robust Classication and Win-Win Results Akshay Degwekar Preetum Nakkiran Vinod Vaikuntanathan June 6, 2019 Abstract We continue the study of statistical/computational tradeos in learning robust classiers, following the recent work of Bubeck, Lee, Price and Razenshteyn who showed examples of classication tasks where (a) an ecient robust classier exists, in the small-perturbation regime ; (b) a non-robust classier can be learned eciently; but (c) it is computationally hard to learn a robust classier, assuming the hardness of factoring large numbers. Indeed, the question of whether a robust classier for their task exists in the large perturbation regime seems related to important open questions in computational number theory. In this work, we extend their work in three directions. First, we demonstrate classication tasks where computationally ecient robust classication is impossible, even when computationally unbounded robust classiers exist. For this, we rely on the existence of average-case hard functions, requiring no cryptographic assumptions. Second, we show hard-to-robustly-learn classication tasks in the large-perturbation regime . Namely, we show that even though an ecient classier that is very robust (namely, tolerant to large perturbations) exists, it is computationally hard to learn any non-trivial robust classier. Our rst construction relies on the existence of one-way functions, a minimal assumption in cryptography, and the second on the hardness of the learning parity with noise problem. In the latter setting, not only does a non-robust classier exist, but also an ecient algorithm that generates fresh new labeled samples given access to polynomially many training examples (termed as generation by Kearns et. al. (1994)). Third, we show that any such counterexample implies the existence of cryptographic primitives such as one-way functions or even forms of public-key encryption. This leads us to a win-win scenario: either we can quickly learn an ecient robust classier, or we can construct new instances of popular and useful cryptographic primitives. This work is a merge of [DV19] and [Nak19].arXiv:1902.01086v2  [stat.ML]  5 Jun 2019Contents 1 Introduction 1 2 Our Results 2 2.1 Existence (World 2) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2 2.2 Learnability (World 4) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3 2.3 A Win-Win Result . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3 2.4 Related Work. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4 3 Our Techniques 5 3.1 The BLPR Classication Task . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5 3.2 Denitions: Robust Classication . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6 3.3 Unlearnability From Pseudorandom Functions and Error Correcting Codes . . . . . 6 3.4 Non-Existence of Robust Classiers from Average-Case Hardness . . . . . . . . . . . 7 3.5 From Hardness of Decoding under Noise. . . . . . . . . . . . . . . . . . . . . . . . . . 8 3.6 Converse: Cryptography from Hardness of Robust Classication. . . . . . . . . . . . 10 4 Denitions 11 4.1 Learning & Classication . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11 4.2 Hardness of Ecient Robust Classication . . . . . . . . . . . . . . . . . . . . . . . . 12 5 Learning Parity with Noise 13 5.1 Assumption Denition and Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . 13 5.2 No Ecient Robust Classier Exists . . . . . . . . . . . . . . . . . . . . . . . . . . . 16 5.3 Ecient Robust Classier Exists but is Hard to Learn . . . . . . . . . . . . . . . . . 17 6 Learning with Errors 19 6.1 Preliminaries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19 6.2 No Ecient Robust Classier Exists . . . . . . . . . . . . . . . . . . . . . . . . . . . 20 6.3 An Ecient Robust Classier Exists but is Hard to Learn . . . . . . . . . . . . . . . 20 7 Using Pseudorandom Functions and Error Correcting Codes 22 8 Using Average-Case Hardness and Error Correcting Codes 24 9 Cryptography from Robustly Hard Tasks 26 A A Description of BLPR Example and the Blum-Blum-Shub PRG. 30 i1 Introduction The basic task in learning theory is to learn a classier given a dataset. Namely, given a labeled datasetf(Xi;f(Xi))gi2[n]wherefis the unknown ground-truth and Xiare drawn i.i.d. from a distribution D, learn a classier hso as to (approximately) minimize :=P XD[h(X)6=f(X)] Adversarial machine learning is harder in that the learned classier is required to be robust . Namely, it has to produce the right answer even under bounded perturbations (under some distance measure) of the sample XD. That is, the goal is to learn a classier hso as to (approximately) minimize :=P XD[9Y2B(X;") s.t.h(Y)6=f(Y)] whereB(X;") =fY:d(X;Y )ganddis the distance measure in question. Learning robust classiers is an important question given a large number of attacks against practical machine learning systems that show how to minimally perturb a sample Xso that classiers output the wrong prediction with high probability. Such attacks were rst discovered in the context of spam ltering and malware classication [DDS+04, LM05, BR18] and more recently, following [GSS, SZS+13], in image classication, voice recognition and many other domains. This state of aairs raises a slew of questions in learning theory. Fix a concept class Fand a distribution Dfor which ecient (non-robust) learning is possible. Do there exist robust classiers forF? Do there exist eciently computable robust classiers for F? Pushing the envelope further, can such classiers be learned with small sample-complexity? and nally, is the learning algorithm computationally ecient? The answer to these questions give rise to ve possible worlds of robust learning, rst postulated in two recent works [BPR18] and [BLPR18], henceforth referred to as BPR and BLPR respectively.1This is the starting point of our work. World 1.No robust classiers exist, regardless of computational or sample-eciency considerations. [FFF18] show a learning task in this world, namely one where computationally ecient non-robust classication is possible, no robust classiers exist. On the other hand, for natural learning tasks, humans seem to be robust classiers that tolerate non-zero error rate , indeed even ecient robust classiers; see [BPR18] for a more detailed discussion. World 2.Robust classiers exist, but they are computationally inecient. We demonstrate learning tasks in this world. World 3.Computationally ecient robust classiers exist, but learning them incurs large sample complexity. [SST+18] show a learning task where a computationally ecient robust classier exists, but learning it requires polynomially more samples than non-robust learning. On the other hand, [BPR18] show that this gap cannot be more than linear in the dimension; see [BPR18] for a more detailed discussion. World 4.Computationally ecient robust classiers exist, and can be learned sample-eciently, but training is computationally inecient. [BLPR18] show a learning task in this world. However, as we observe below, their computationally ecient robust classier only recovers from a very small number (indeed, a constant number) of perturbations. Whether there 1To be precise, [BPR18] postulated four worlds, namely worlds 1 and 3{5. Subsequent work of [BLPR18] added the second world. 1exists an ecient robust classier for their task that recovers from large perturbations seems related to long-standing open questions in computational number theory [Hen19, Gre13]. As our second result, we show two examples of learning tasks that live in this world; more details in Section 2. World 5.The best world of all, in which there exist ecient algorithms both for classication and training, and the sample complexity is small (but it could be that we haven't discovered the right algorithm just yet.) We want to understand { are we likely to nd learning tasks such as the ones [BLPR18] and we demonstrate in the wild? To that end, our third result is a win-win statement: namely, any such learning task gives rise to a cryptographic object{ either a simple one like a one-way function or a complex one like public-key encryption. We proceed to describe the three results in more detail. But before we do so, a word of warning. We and [BLPR18] dene these ve worlds in a coarse way using polynomial-time as a proxy for computational eciency, and a large constant accuracy as a proxy for successful classication. (We should also mention that [BPR18] use SQ-learning as a dierent proxy for computationally ecient learning.) One could be more careful and speak of running-time/accuracy tradeos in the dierent worlds, but since our goal here is to show broad counterexamples, we do not attempt to do such a ne-grained distinction. 2 Our Results We explore the relationship of computational constraints and ecient robust classication. The setting we consider consists of two distributions D0;D1and the classier has to correctly classify inputs from both. We consider the two facets to ecient robust classication: (1) existence: do ecient robust classiers exist? (corresponds to World 2) and (2) learnbility: can we learn robust classiers eciently? We show three sets results on which we elaborate below. 2.1 Existence (World 2) In terms of feasibility, we show that there are learning tasks where while inecient robust classication is possible, no ecient robust classiers exist . That is, we demonstrate learning tasks in World 2. We can show the following: Theorem 2.1 (Informal) .There exist classication tasks over where (1) ecient non-robust classiers exist, (2) no ecient robust classier exists, but (3) inecient robust classiers exist. This result does not require cryptographic assumptions, and relies only on the existence of average-case hard functions and good error-correcting codes. In fact, this result scales down to more ne-grained notions of eciency than polynomial-time. All that is required is a function that is average-case hard for the \ecient" class, but computable by the \inecient" class. We give several examples of such learning tasks, including some examples that require cryptographic assumptions but obtain other desirable properties (such as obtaining tasks with ecientlysamplable distributions). More details are given in Sections 3.4, 3.5, 5, 6 and 8. 22.2 Learnability (World 4) We want to understand the hardness of learning an ecient robust classier when it exists. The starting point of this work was the BLPR work [BLPR18]. They showed that under cryptographic assumptions, there exists a learning task which admits ecient robust classiers, but it is computationally infeasible to train such a classier. More precisely, they showed that there exists a classication task (over f0;1gn) where (a) learning any non-trivial robust classier is computationally infeasible while (b) an ecient robust classier exists. Unfortunately, we observe that their robust classier is ecient only when correcting a constant number of errors. Indeed, as we explain in Section 3.1, the question of whether there exists a computationally ecient robust classier for their task correcting even !(1) bits of error is an important open question in computational number theory that has received some attention in the cryptanalysis community [Gre13, Hen19]. The BPLR construction can be rescued using error correcting codes to enable ecient robust classiers robust to large (constant fraction) perturbations. Our results strengthen theirs in two ways: we can weaken the required cryptographic assumption to that one-way functions exist and demonstrate tasks where the gap between learning and robust classication is more: in that ecient learning algorithms can learn to not only classify, but also to generate fresh samples from the distributions. Theorem 2.2 (Informal) .Under the minimal cryptographic assumption that one-way functions, there exist classication tasks over f0;1gmwhere (1) it is easy to learn a non-robust classier (2) an ecient robust classier that tolerates m=8-sized perturbations exists, and (3) it is computationally hard to learn any non-trivial robust classier. Theorem 2.3 (Informal) .Assuming Learning Parity with Noise (or Learning with Errors) in the \public-key" regime of parameters, there exist classication tasks on f0;1gmwhere (1) it is easy to learn a non-robust classier. (2) an ecient robust classier tolerating O(pm)-errors exists, and (3) it is computationally hard to learn any non-trivial robust classier. Furthermore, it is easy to learn generators/evaluators for the non-robust distributions.2 We elaborate on the dierences between the two theorems in the techniques section. Brie y, there are three key dierences: Theorem 2.3 requires a stronger assumption, but gives a more \natural" example where the resulting distributions are \more easier" to learn non-robustly. In particular, it is easy to learn how to generate fresh samples from the two distributions, something that the one-way function based example cannot support. This is important because we want to separate the complexity of learning the distribution from that of robust classication. And here, these distributions can be learned in a stronger sense while still being hard to classify under adversarial perturbations. 2.3 A Win-Win Result Finally, we want to understand { Are we likely to nd such learning tasks in the wild? To that end, we show a converse to our results. Namely, Theorem 2.4 (Informal) .Any computational task where an ecient robust classier exists, but is hard to learn one in polynomial time implies one-way functions, and hence symmetric key cryptography. 2Generators and Evaluators [KMR+94], are algorithms that can sample from the distribution and output the pdf of the distribution respectively. 3Furthermore, if the learning task satises certain natural properties, it gives us (a certain weaker form of) public-key cryptography as well! It would be very surprising to us if public-key cryptography (and even one-way functions) arise out of natural classication tasks on, say, images. Thus, perhaps uncharacteristically for cryptographers, we oer a possible (optimistic) interpretation of this state of aairs: namely, that fornatural learning tasks where there exists a robust classifer, it can also be eciently found, we just haven't gured out the right algorithm yet. An important caveat is due here: our denition of hardness of learning a robust classier is a strong one: it requires that the perturbing adversary be constructive and universal. Our classication tasks do satisfy this denition, and that only makes them stronger. On the other hand, it does make our converse weaker. More details are given in Section 3. 2.4 Related Work. The works closest to ours are [BPR18, BLPR18]. We discuss them last. Adversarial Examples. The problem of adversarial classication ws rst considered by [DDS+04]. Starting with [SZS+13], there is a large body of work demonstrating the existence of small adversarial perturbations in neural networks that cause them to misclassify examples with high condence. There have been various approaches proposed against such perturbations and 