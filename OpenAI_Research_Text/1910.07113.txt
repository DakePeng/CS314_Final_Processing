SOLVING RUBIK ‚ÄôSCUBE WITH A ROBOT HAND A P REPRINT OpenAI Ilge Akkaya, Marcin Andrychowicz, Maciek Chociej, Mateusz Litwin, Bob McGrew, Arthur Petron, Alex Paino, Matthias Plappert, Glenn Powell, Raphael Ribas, Jonas Schneider, Nikolas Tezak, Jerry Tworek, Peter Welinder, Lilian Weng, Qiming Yuan, Wojciech Zaremba, Lei Zhang October 17, 2019 Figure 1: A Ô¨Åve-Ô¨Ångered humanoid hand trained with reinforcement learning and automatic domain randomization solving a Rubik‚Äôs cube. ABSTRACT We demonstrate that models trained only in simulation can be used to solve a manipulation problem of unprecedented complexity on a real robot. This is made possible by two key components: a novel algorithm, which we call automatic domain randomization (ADR) and a robot platform built for machine learning. ADR automatically generates a distribution over randomized environments of ever-increasing difÔ¨Åculty. Control policies and vision state estimators trained with ADR exhibit vastly improved sim2real transfer. For control policies, memory-augmented models trained on an ADR-generated distribution of environments show clear signs of emergent meta-learning at test time. The combination of ADR with our custom robot platform allows us to solve a Rubik‚Äôs cube with a humanoid robot hand, which involves both control and state estimation problems. Videos summarizing our results are available: https://openai.com/blog/solving-rubiks-cube/ 1 Introduction Building robots that are as versatile as humans remains a grand challenge of robotics. While humanoid robotics systems exist [ 28,99,110,95,5], using them in the real world for complex tasks remains a daunting challenge. Machine learning Authors are listed alphabetically. We include a detailed contribution statement at the end of this manuscript. Please cite as OpenAI et al., and use the following bibtex for citation: https://openai.com/bibtex/openai2019rubiks.bibarXiv:1910.07113v1  [cs.LG]  16 Oct 2019APREPRINT OCTOBER 17, 2019 Figure 2: System Overview. (a) We use automatic domain randomization (ADR) to generate a growing distribution of simulations with randomized parameters and appearances. We use this data for both the control policy and vision-based state estimator. (b) The control policy receives observed robot states and rewards from the randomized simulations and learns to solve them using a recurrent neural network and reinforcement learning. (c) The vision-based state estimator uses rendered scenes collected from the randomized simulations and learns to predict the pose as well as face angles of the Rubik‚Äôs cube using a convolutional neural network (CNN), trained separately from the control policy. (d) To transfer to the real world, we predict the Rubik‚Äôs cube‚Äôs pose from 3 real camera feeds with the CNN and measure the robot Ô¨Ångertip locations using a 3D motion capture system. The face angles that describe the internal rotational state of the Rubik‚Äôs cube are provided by either the same vision state estimator orthe Giiker cube, a custom cube with embedded sensors and feed it into the policy network. 2APREPRINT OCTOBER 17, 2019 has the potential to change this by learning how to use sensor information to control the robot system appropriately instead of hand-programming the robot using expert knowledge. However, learning requires vast amount of training data, which is hard and expensive to acquire on a physical system. Collecting all data in simulation is therefore appealing. However, the simulation does not capture the environment or the robot accurately in every detail and therefore we also need to solve the resulting sim2real transfer problem. Domain randomization techniques [ 106,80] have shown great potential and have demonstrated that models trained only in simulation can transfer to the real robot system. In prior work, we have demonstrated that we can perform complex in-hand manipulation of a block . This time, we aim to solve the manipulation and state estimation problems required to solve a Rubik‚Äôs cube with the Shadow Dexterous Hand  using only simulated data. This problem is much more difÔ¨Åcult since it requires signiÔ¨Åcantly more dexterity and precision for manipulating the Rubik‚Äôs cube. The state estimation problem is also much harder as we need to know with high accuracy what the pose and internal state of the Rubik‚Äôs cube are. We achieve this by introducing a novel method for automatically generating a distribution over randomized environments for training reinforcement learning policies and vision state estimators. We call this algorithm automatic domain randomization (ADR). We also built a robot platform for solving a Rubik‚Äôs cube in the real world in a way that complements our machine learning approach. Figure 2 shows an overview of our system. We investigate why policies trained with ADR transfer so well from simulation to the real robot. We Ô¨Ånd clear signs of emergent learning that happens at test time within the recurrent internal state of our policy. We believe that this is a direct result of us training on an ever-growing distribution over randomized environments with a memory-augmented policy. In other words, training an LSTM over an ADR distribution is implicit meta-learning. We also systematically study and quantify this observation in our work. The remainder of this manuscript is structured as follows. Section 2 introduces two manipulation tasks we consider here. Section 3 describes our physical setup and Section 4 describes how our setup is modeled in simulation. We introduce a new algorithm called automatic domain randomization (ADR), in Section 5. In Section 6 and Section 7 we describe how we train control policies and vision state estimators, respectively. We present our key quantitative and qualitative results on the two tasks in Section 8. In Section 9 we systematically analyze our policy for signs of emergent meta-learning. Section 10 reviews related work and we conclude with Section 11. If you are mostly interested in the machine learning aspects of this manuscript, Section 5, Section 6, Section 7, Section 8, and Section 9 are especially relevant. If you are interested in the robotics aspects, Section 3, Section 4, and Section 8.4 are especially relevant. 2 Tasks In this work, we consider two different tasks that both use the Shadow Dexterous Hand : the block reorientation task from our previous work [ 77,84] and the task of solving a Rubik‚Äôs cube. Both tasks are visualized in Figure 3. We brieÔ¨Çy describe the details of each task in this section. 2.1 Block Reorientation The block reorientation task was previously proposed in  and solved on a physical robot hand in . We brieÔ¨Çy review it here; please refer to the aforementioned citations for additional details. The goal of the block reorientation task is to rotate a block into a desired goal orientation. For example, in Figure 3a, the desired orientation is shown next to the hand with the red face facing up, the blue face facing to the left and the green face facing forward. A goal is considered achieved if the block‚Äôs rotation matches the goal rotation within 0:4radians. After a goal is achieved, a new random goal is generated. 2.2 Rubik‚Äôs Cube We introduce a new and signiÔ¨Åcantly more difÔ¨Åcult problem in this work: solving a Rubik‚Äôs cube2with the same Shadow Dexterous Hand. In brief, a Rubik‚Äôs cube is a puzzle with 6 internal degrees of freedom. It consists of 26cubelets that are connected via a system of joints and springs. Each of the 6 faces of the cube can be rotated, allowing the Rubik‚Äôs cube to be scrambled . A Rubik‚Äôs cube is considered solved if all 6 faces have been returned to a single color each. Figure 3b depicts a Rubik‚Äôs cube that is a single 90degree rotation of the top face away from being solved. 2https://en.wikipedia.org/wiki/Rubik‚Äôs_Cube 3APREPRINT OCTOBER 17, 2019 (a) Block reorientation  (b) Rubik‚Äôs cube Figure 3: Visualization of the block reorientation task (left) and the Rubik‚Äôs cube task (right). In both cases, we use a single Shadow Dexterous Hand to solve the task. We also depict the goal that the policy is asked to achieve in the upper left corner. We consider two types of subgoals : Arotation corresponds to rotating a single face of the Rubik‚Äôs cube by 90degrees in the clockwise or counter-clockwise direction. A Ô¨Çipcorresponds to moving a different face of the Rubik‚Äôs cube to the top. We found rotating the top face to be far simpler than rotating other faces. Thus, instead of rotating arbitrary faces, we combine together a Ô¨Çip and a top face rotation in order to perform the desired operation. These subgoals can then be performed sequentially to eventually solve the Rubik‚Äôs cube. The difÔ¨Åculty of solving a Rubik‚Äôs cube obviously depends on how much it has been scrambled before. We use the ofÔ¨Åcial scrambling method used by the World Cube Association3to obtain what they refer to as a fair scramble . A fair scramble typically consists of around 20moves that are applied to a solved Rubik‚Äôs cube to scramble it. When it comes to solving the Rubik‚Äôs cube, computing a solution sequence can easily be done with existing software libraries like the Kociemba solver . We use this solver to produce a solution sequence of subgoals for the hand to perform. In this work, the key problem is thus about sensing and control, notÔ¨Ånding the solution sequence. More concretely, we need to obtain the state of the Rubik‚Äôs cube (i.e. its pose as well as its 6 face angles) and use that information to control the robot hand such that each subgoal is successfully achieved. 3 Physical Setup Having described the task, we next describe the physical setup that we use to solve the block and the Rubik‚Äôs cube in the real world. We focus on the differences that made it possible to solve the Rubik‚Äôs cube since  has already described our physical setup for solving the block reorientation task. 3.1 Robot Platform Our robot platform is based on the conÔ¨Åguration described in . We still use the Shadow Dexterous E Series Hand (E3M5R)  as a humanoid robot hand and the PhaseSpace motion capture system to track the Cartesian coordinates of all Ô¨Åve Ô¨Ångertips. We use the same 3 RGB Basler cameras for vision pose estimation. However, a number of improvements have been made since our previous publication. Figure 4a depicts the latest iteration of our robot cage. The cage is now fully contained, i.e. all computers are housed within the system. The cage is also on coasters and can therefore be moved more easily. The larger dimensions of the new cage make calibration of 3https://www.worldcubeassociation.org/regulations/scrambles/ 4APREPRINT OCTOBER 17, 2019 (a) The cage.  (b) The Shadow Dexterous Hand. Figure 4: The latest version of our cage (left) that houses the Shadow Dexterous Hand, RGB cameras, and the PhaseSpace motion capture system. We made some modiÔ¨Åcations to the Shadow Dexterous Hand (right) to improve reliability for our setup by moving the PhaseSpace LEDs and cables inside the Ô¨Ångers and by adding rubber to the Ô¨Ångertips. the PhaseSpace motion capture system easier and help prevent disturbing calibration when taking the hand in and out of the cage. We have made a number of customizations to the E3M5R since our last publication (see also Figure 4b). We moved routing of the cables that connect the PhaseSpace LEDs on each Ô¨Ångertip to the PhaseSpace micro-driver within the hand, thus reducing the wear and tear on those cables. We worked with The Shadow Robot Company4to improve the robustness and reliability of some components for which we noticed breakages over time. We also modiÔ¨Åed the distal part of the Ô¨Ångers to extend the rubber area to cover a larger span to increase the grip of the hand when it interacts with an object. We increased the diameter of the wrist Ô¨Çexion/extension pulley in order to reduce tendon stress which has extended the life of the tendon to more than three times its typical mean time before failure (MTBF). Finally, the tendon tensioners in the hand have been upgraded and this has improved the MTBF of the Ô¨Ånger tendons by approximately Ô¨Åve to ten times. We also made improvements to our software stack that interfaces with the E3M5R. For example, we found that manual tuning of the maximum torque that each motor can exercise was superior to our automated methods in avoiding physical breakage and ensuring consistent policy performance. More concretely, torque limits were minimized such that the hand can reliably achieve a series of commanded positions. We also invested in real-time system monitoring so that issues with the physical setup could be identiÔ¨Åed and resolved more quickly. We describe our monitoring system in greater detail in Appendix A. 3.2 Giiker Cube Sensing the state of a Rubik‚Äôs cube from vision only is a challenging task. We therefore use a ‚Äúsmart‚Äù Rubik‚Äôs cube with built-in sensors and a Bluetooth module as a stepping stone: We used this cube while face angle predictions from vision were not yet ready in order to continue work on the control policy. We also used the Giiker cube for some of our experiments to test the control policy without compounding errors made by the vision model‚Äôs face angle predictions (we always use the vision model for pose estimation). Our hardware is based on the Xiaomi Giiker cube.5This cube is equipped with a Bluetooth module and allows us to sense the state of the Rubik‚Äôs cube. However, it only has a face angle resolution of 90, which is not sufÔ¨Åcient for state tracking purposes on the robot setup. We therefore replace some of the components of the original Giiker cube with custom ones in order to achieve a tracking accuracy of approximately 5. Figure 5a shows the components of the unmodiÔ¨Åed Giiker cube and our custom replacements side by side, as well as the assembled modiÔ¨Åed Giiker cube. Since we only use our modiÔ¨Åed version, we henceforth refer to it as only ‚ÄúGiiker cube‚Äù. 4https://www.shadowrobot.com/ 5https://www.xiaomitoday.com/xiaomi-giiker-m3-intelligent-rubik-cube-review/ 5APREPRINT OCTOBER 17, 2019 (a) The components of the Giiker cube.  (b) An assembled Giiker cube while charging. Figure 5: We use an off-the-shelf Giiker cube but modify its internals (subÔ¨Ågure a, right) to provider higher resolution for the 6 face angles. The components from left to right are (i) bottom center enclosure, (ii) lithium polymer battery, (iii) main PCBa with BLE, (iv) top center enclosure, (v) cubelet bottom, (vi) compression spring, (vii) contact brushes, (viii) absolute resistive rotary encoder, (ix) locking cap, (x) cubelet top. Once assembled, the Giiker cube can be charged with its ‚Äúheadphones on‚Äù (right). 3.2.1 Design We have redesigned all parts of the Giiker cube but the exterior cubelet elements. The central support was redesigned to move the parting line off of the central line of symmetry to facilitate a more friendly development platform because the off-the-shelf design would have required de-soldering in order to program the microcontroller. The main Bluetooth and signal processing board is based on the NRF52 integrated circuit . Six separately printed circuit boards (Figure 6b) were designed to improve the resolution from 90to5using an absolute resistive encoder layout. The position is read with a linearizing circuit shown in Figure 6a. The linearized, analog signal is then read by an ADC pin on the microcontroller and sent as a face angle over the Bluetooth Low Energy (BLE) connection to the host. The custom Ô¨Årmware implements a protocol that is based on the Nordic UART service (NUS) to emulate a serial port over BLE . We then use a Node.js6based client application to periodically request angle readings from the UART 