Learning to summarize from human feedback Nisan StiennonLong OuyangJeff WuDaniel M. ZieglerRyan Lowe Chelsea VossAlec Radford Dario Amodei Paul Christiano OpenAI Abstract As language models become more powerful, training and evaluation are increasingly bottlenecked by the data and metrics used for a particular task. For example, summarization models are often trained to predict human reference summaries and evaluated using ROUGE, but both of these metrics are rough proxies for what we really care about—summary quality. In this work, we show that it is possible to signiﬁcantly improve summary quality by training a model to optimize for human 