Generative Language Models and Automated Inﬂuence Operations: Emerging Threats and Potential Mitigations Josh A. Goldstein1,3, Girish Sastry2, Micah Musser1, Renée DiResta3, Matthew Gentzel2, and Katerina Sedova1 1Georgetown University’s Center for Security and Emerging Technology 2OpenAI 3Stanford Internet Observatory January 2023 Workshop Participants: Steven Adler, Shahar Avin, John Bansemer, Chris Bregler, Miles Brundage, Sam Gregory, Shelby Grossman, Ariel Herbert-Voss, Yacine Jernite, Claire Leibowicz, Connor Leahy, Herb Lin, Drew Lohn, Meg Mitchell, Amnon Morag, Alex Newhouse, Helen Ngo, Aviv Ovadya, Cooper Raterink, Yoel Roth, Bob Rotsted, Elizabeth Seger, and Raymond Serrato. Acknowledgements: We thank participants in the October 2021 workshop that we convened for informing our understanding of various threats and mitigations. We also thank many workshop participants for providing feedback on a draft of this paper. For additional feedback on the paper, we thank Deepesh Chaudhari, Jeff Ding, Tyna Elondou, Shengli Hu, Daniel Kokotajlo, Gretchen Krueger, Pamela Mishkin, Ronald Robertson, Sarah Shoker, Samuel Wolrich, and Jenny Xiao. Josh Goldstein began working on the project as a postdoctoral fellow at Stanford, and continued work as a research fellow with Georgetown CSET’s CyberAI Project. Matthew Gentzel completed his contributions while contracting for OpenAI, and is now at Longview Philanthropy. Katerina Sedova completed her contributions to this project while she was a research fellow with Georgetown CSET’s CyberAI Project and before she entered U.S. government service. All errors remain our own. Lead authors contributed equally.arXiv:2301.04246v1  [cs.CY]  10 Jan 2023Contents Executive Summary 1 1 Introduction 5 1.1 Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5 1.2 Threats and Mitigations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6 1.3 Scope and Limitations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7 1.4 Outline of the Report . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8 2 Orienting to Inﬂuence Operations 9 2.1 What Are Inﬂuence Operations, and Why Are They Carried Out? . . . . . . . . . . . . . . . . 9 2.2 Inﬂuence Operations and Impact . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11 3 Recent Progress in Generative Models 15 3.1 What Are Generative Models, and How Are They Built? . . . . . . . . . . . . . . . . . . . . . 15 3.2 Access and Diffusion of Generative Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19 4 Generative Models and Inﬂuence Operations 22 4.1 Language Models and the ABCs of Disinformation . . . . . . . . . . . . . . . . . . . . . . . . . 22 4.2 Expected Developments and Critical Unknowns . . . . . . . . . . . . . . . . . . . . . . . . . . 29 5 Mitigations 38 5.1 A Framework for Evaluating Mitigations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38 5.2 Model Design and Construction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42 5.3 Model Access . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49 5.4 Content Dissemination . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53 5.5 Belief Formation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59 6 Conclusions 63 6.1 Language Models Will Likely Change Inﬂuence Operations . . . . . . . . . . . . . . . . . . . 63 6.2 There Are No Silver Bullet Solutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 64 6.3 Collective Responses Are Needed . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 64 6.4 Mitigations Must Address Demand As Well As Supply . . . . . . . . . . . . . . . . . . . . . . . 65 6.5 Further Research Is Necessary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 65 