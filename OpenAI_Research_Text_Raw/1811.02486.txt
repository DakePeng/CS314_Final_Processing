Concept Learning with Energy-Based Models
Igor Mordatch
OpenAI
San Francisco, CA
mordatch@openai.com
Abstract
Many hallmarks of human intelligence, such as generalizing from limited expe-
rience, abstract reasoning and planning, analogical reasoning, creative problem
solving, and capacity for language require the ability to consolidate experience into
concepts , which act as basic building blocks of understanding and reasoning. We
present a framework that deÔ¨Ånes a concept by an energy function over events in the
environment, as well as an attention mask over entities participating in the event.
Given few demonstration events, our method uses inference-time optimization pro-
cedure to generate events involving similar concepts or identify entities involved in
the concept. We evaluate our framework on learning visual, quantitative, relational,
temporal concepts from demonstration events in an unsupervised manner. Our
approach is able to successfully generate and identify concepts in a few-shot setting
and resulting learned concepts can be reused across environments. Example videos
of our results are available at sites.google.com/site/energyconceptmodels
1 Introduction
Many hallmarks of human intelligence, such as generalizing from limited experience, abstract
reasoning and planning, analogical reasoning, creative problem solving, and capacity for language
and explanation are still lacking in the artiÔ¨Åcial intelligent agents. We, as others [ 25,22,21] believe
what enables these abilities is the capacity to consolidate experience into concepts , which act as basic
building blocks of understanding and reasoning.
Examples of concepts include visual ( "red" or"square" ), spatial ( "inside" ,"on top of" ), temporal
("slow" ,"after" ), social ( "aggressive" ,"helpful" ) among many others [ 22]. These concepts can be
either identiÔ¨Åed or generated - one can not only Ô¨Ånd a square in the scene, but also create a square,
either physical or imaginary. Importantly, humans also have a largely unique ability to combine
concepts compositionally ( "red square" ) and recursively ( "move inside moving square" ) - abilities
reÔ¨Çected in the human language. This allows expressing an exponentially large number of concepts,
and acquisition of new concepts in terms of others. We believe the operations of identiÔ¨Åcation,
generation, composition over concepts are the tools with which intelligent agents can understand and
communicate existing experiences and reason about new ones.
Crucially, these operations must be performed on the Ô¨Çy throughout the agent‚Äôs execution, rather
than merely being a static product of an ofÔ¨Çine training process. Execution-time optimization, as in
recent work on meta-learning [ 6] plays a key role in this. We pose the problem of parsing experiences
into an arrangement of concepts as well as the problems of identifying and generating concepts as
optimizations performed during execution lifetime of the agent. The meta-level training is performed
by taking into account such processes in the inner level.
SpeciÔ¨Åcally, a concept in our work is deÔ¨Åned by an energy function taking as input an event
conÔ¨Åguration (represented as trajectories of entities in the current work), as well as an attention mask
over entities in the event. Zero-energy event and attention conÔ¨Ågurations imply that event entities
selected by the attention mask satisfy the concept. Compositions of concepts can then be created byarXiv:1811.02486v1  [cs.AI]  6 Nov 2018simply summing energies of constituent concepts. Given a particular event, optimization can be used
to identify entities belonging to a concept by solving for attention mask that leads to zero-energy
conÔ¨Åguration. Similarly, an example of a concept can be generated by optimizing for a zero-energy
event conÔ¨Åguration. See Figure 1 for examples of these two processes.
The energy function deÔ¨Ånes a family of concepts, from which a particular concept is selected with a
speciÔ¨Åc concept code. Encoding of event and attention conÔ¨Ågurations can be achieved by execution-
time optimization over concept codes. Once an event is encoded, the resulting concept code structure
can be used to re-enact the event under different initial conÔ¨Ågurations (task of imitation learning),
recognize similar events, or concisely communicate the nature of the event. We believe there is a
strong link between concept codes and language, but leave it unexplored in this work.
At the meta level, the energy function is the only entity that needs to be learned. This is different from
generative model or inverse reinforcement learning approaches, which typically also learn an explicit
generator/policy function, whereas we deÔ¨Åne it implicitly via optimization. Our advantage as that the
learned energy function can be reused in other domains, for example using a robot platform to re-
enact concepts in the physical world. Such transfer is not possible with an explicit generation/policy
function, as it is domain-speciÔ¨Åc.
x 0 a x 1 x 0 a x 1 
generation identification 
Figure 1: Examples of generation and identiÔ¨Åcation processes for a "square" concept. a) Given initial
statex0and attention mask a, square consisting of entities in ais formed via optimization over x1.
b) Given states x, entities comprising a square are found by optimization over attention mask a.
2 Related Work
We draw upon several areas for inspiration in our work, including energy-based models, concept
learning, inverse reinforcement learning and meta-learning.
Energy-based modelling approaches have a long history in machine learning, commonly used for
density modeling [ 4,16,26,9]. These approaches typically aim to learn a function that assigns low
energy values to inputs in the data distribution and high energy values to other inputs. The resulting
models can then be used to either discriminate whether or not a query input comes from the data
distribution, or to generate new samples from the data distribution. One common choice for sampling
procedure is Markov Chain Monte Carlo (MCMC), however it suffers from slow mixing and often
requires many iterative steps to generate samples [ 26]. Another choice is to train a separate network
to generate samples [ 18]. Generative Adversarial Networks [ 11] can be thought of as instances
of this approach [ 7]. The key difÔ¨Åculty in training energy-based models lies in estimating their
partition function, with many approaches relying on the sampling procedure to estimate it or further
approximations [ 16]. Our approach avoids both the slow mixing of MCMC and the need to train a
separate network. We use sampling procedure based on gradient of the energy (which mixes much
faster than gradient-free MCMC), while training the energy function to have a gradient Ô¨Åeld that
produces good samples.
The problem of learning and reasoning over concepts or other abstract representations has long been
of interest in machine learning (see [ 21,3] for review). Approaches based on Bayesian reasoning
have notably been applied for numerical concepts [ 32]. A recent framework of [ 15] focuses on visual
concepts such as color and shape, where concepts are deÔ¨Åned in terms of distributions over latent
variables produced by a variational autoencoder. Instead of focusing solely on visual concepts from
pixel input, our work explores learning of concepts that involve complex interaction of multiple
entities.
Our method aims to learn concepts from demonstration events in the environment. A similar problem
is tackled by inverse reinforcement learning (IRL) approaches, which aim to infer an underlying cost
2function that gives rise to demonstrated events. Our method‚Äôs concept energy functions are analogous
to the cost or negative of value functions recovered by IRL approaches. Under this view, multiple
concepts can easily be composed simply by summing their energy functions. Concepts are then
enacted in our approach via energy minimization, mirroring the application a forward reinforcement
learning step in IRL methods. Max entropy [ 36] is a common IRL formulation, and our method
closely resembles recent instantiations of it [8, 5].
Our method relies on performing inference-time optimization processes for concept generation and
identiÔ¨Åcation, as well as for determining which concepts are involved in an event. The training
is performed by taking behavior of these inner optimization processes into account, similar to the
meta-learning formulations of [ 6]. Relatedly, iterative processes have been explored in the context of
control [30, 29, 34, 14, 28] and image generation [13].
3 Energy-Based Concept Models
Concepts operate over events, which in this work is a trajectory of Tstates x=
x0;:::;xT
. Each
state contains a collection of Nentities xt= [x0;:::;xN]and each entity xt
ican contain information
such as position and color of the entity. Considering entire trajectories and entities allows us to model
temporal or relational concepts, unlike work that focuses on visual concepts [ 15]. Attention over
entities in the event is speciÔ¨Åed by a mask a2RNover each of the entities.
Existence of a particular concept is given by energy function E(x;a;w)2R+, where parameter
vector wspeciÔ¨Åes a particular concept from a family. The interpretation of wis similar to that of a
code in an autoencoder. E(x;a;w) = 0 when state trajectory xunder attention mask aover entities
satisÔ¨Åes the concept w. Otherwise, E(x;a;w)>0. The conditional probabilities of a particular
event conÔ¨Åguration belonging to a concept and a particular attention mask identifying a concept are
given by the Boltzmann distributions:
p(xja;w)/expf E(x;a;w)gp(ajx;w)/expf E(x;a;w)g (1)
Given concept code w, the energy function can be used for both generation and identiÔ¨Åcation of a
concept implicitly via optimization (see Figure 1):
x(a) = argmin
xE(x;a;w) a(x) = argmin
aE(x;a;w) (2)
Samples from distributions in (1) can be generated via stochastic gradient Langevin dynamics,
effectively performing stochastic minimization in (2):
~xx(ja;w) =xK;xk=xk 1+
2rxE(x;a;w) +!k
~aa(jx;w) =aK;ak=ak 1+
2raE(x;a;w) +!k; !kN(0;) (3)
This stochastic optimization procedure is performed during execution time of the algorithm and is
reminiscent of the Monte Carlo sampling procedures in prior work on energy-based models [ 16,26,9].
The procedure differs from approaches that use explicit generator functions [ 4,20,18] or explicit
attention mechanisms, such as dot product attention [24].
It is shown in [ 35] that ~xand~awill approach samples from posterior distributions pasK7!1 and
7!0. However in practice it is only possible to execute the dynamics for a Ô¨Ånite number of steps
(we useK= 10 in all our experiments). This truncated procedure results in samples drawn from a
biased distribution, which we call and which may not be equal to p. Similar issues of slow mixing
are also present in prior work, which typically uses non-differentiable sampling procedures. In our
case, the sampling procedure in equation (3) can be differentiated and can be trained to produce
samples close to true distribution p.
There are many possible choices for the energy function as long as it is non-negative. The speciÔ¨Åc
form we use in this work is based on relation network architecture [ 27] for its ability to easily capture
interactions between pairs of entities
E(x;a;w) =f(X
t;i;j(ai)(aj)g(xt
i;xt
j;w);w)2(4)
Wherefandgare multi-layer neural networks that each take concept code as part of their input. is
the sigmoid function and is used to gate the entity pairs by their attention masks.
34 Learning Concepts from Events
To learn concepts from experience grounded in events, we pose a few-shot prediction task. Given
a few demonstration examples Xdemocontaining tuples (x;a)and initial state x0for a new event
inXtrain, the task is to predict attention aand the future state trajectory x1:Tof the new event. The
new event may contain a different conÔ¨Åguration or number of entities, so it is not possible to directly
transfer attention mask, for instance. To simplify notation, we consider prediction of only one future
statex1, although predicting more states is straightforward. The procedure is depicted in Figure 2.
x0x1a x0
?demo event test event x1atest event 
Figure 2: Example of a few-shot prediction task we use to learn concept energy functions.
We follow the maximum entropy inverse reinforcement learning formulation [ 36] and assume demon-
strations are samples from the distributions given by the energy function E. Given an inferred concept
code w(details discussed below), Ô¨Ånding energy function parameters is posed as as maximum
likelihood estimation problem over future state and attention given initial state. The resulting loss for
a particular dataset Xis
LML
p(X;w) =E(x;a)X
 logp 
x1;ajx0;w
(5)
Where the joint probability can be decomposed in terms of probabilities in (1) as
logp 
x1;ajx0;w
= logp 
x1ja;wx
+ logp 
ajx0;wa
;w= [wx;wa] (6)
We use two concept codes, wxandwato specify the joint probability. The interpretation is that
wxspeciÔ¨Åes the concept of the action that happens in the event (i.e. "be in center of" ) while wa
speciÔ¨Åes the argument the action happens over (i.e. "square" ). This is a concept structure or syntax
that describes the event. The concept codes are interchangeable and same concept code can be used
either as action or as an argument because the energy function deÔ¨Åning the concept can either be used
for generation or identiÔ¨Åcation. This importantly allows concepts to be understood from their usage
under multiple contexts.
Conditioned on the two codes concatenated as w, the two log-likelihood terms in (6) can be approxi-
mated as (see Appendix for the derivation)
logp 
x1ja;wx
 
E(x1;a;wx) E(~x;a;wx)
+~xx(ja;wx)
logp 
ajx0;wa
 
E(x0;a;wa) E(x0;~a;wa)
+~aa 
jx0;wa
(7)
Where []+= log(1 + exp())is the softplus operator. This form is similar to contrastive divergence
[16] and structured SVM forms [ 2] and is a special case of guided cost learning formulation [ 8]. The
approximation comes from sample-based estimates of the partition functions for p(x)andp(a).
The above equations make use of truncated and biased gradient-based sampling distributions xand
ain (3) to estimate the respective partition functions. Following [ 8], the approximation error in
these estimates is minimal when KL divergence between biased distribution and true distribution
expf Eg=Zis minimized:
LKL
(X;w) = KL (xjjpx) + KL (ajjpa)
=E(x;a)X
E(~x;a;wx) +E(x0;~a;wa)
+ H [x] + H [a]
~xx(ja;wx);~aa 
jx0;wa
The above equation intuitively encourages sampling distributions to generate samples from low-
energy regions.
4Execution-Time Inference of Concepts Given a set of example events X, the concept codes can
be inferred at execution-time via Ô¨Ånding codes wthat minimizeLMLandLKL. Similar to [ 12], in
this work we only consider positive examples when adapting wand ignore the effect that changing w
has on the sampling distribution . The result is simply minimizing the energy functions wrt wover
the concept example events
w
(X) = argmin
wE(x;a)X
E(x1;a;wx) +E(x0;a;wa)
(8)
This minimization is similar to execution-time parameter adaptation and the inner update of meta-
learning approaches [ 6]. We perform the optimization with stochastic gradient updates similar to
equation (3). This approach again implicitly infers codes at execution time via meta-learning using
only the energy model as opposed to incorporating additional explicit inference networks.
Meta-Level Parameter Optimization We seek probability density functions pthat maximize the
likelihood of training data XviaLML
pand simultaneously we seek sampling distributions that
generate samples from pviaLKL
. In inverse reinforcement learning setting of [ 8] and [ 10], these
two objectives correspond to cost and policy function optimization are treated as separate alternating
optimization problems because they operate over two different functions. However, in our case both
pandare implicitly a functions of the energy model and its parameters , a dependence which we
denote asp()and(). Consequently we can pose the problem as a single joint optimization
min
LML
p()(Xtrain;w
(Xdemo)) +LKL
()(Xtrain;w
(Xdemo)) (9)
We solve the above optimization problem via end-to-end backpropagation, differentiation through
gradient-based sampling procedures. See Figure 3 for an overview of our procedure and appendix for
a detailed algorithm description.
wx0x1
x0a x1a
opt x0x1aE
optconcept inference identification 
generation Œ∏
demo test
test
opt  *
Figure 3: Execution-time inference in our method and the resulting optimization problems.
5 Experiments
The main purpose of our experiments is to investigate 1) whether our single model is able to
learn understanding of wide variety of concepts under multiple contexts, 2) the utility of itera-
tive optimization-based inference processes, and 3) ability to reuse learned concepts on different
environments and actuation platforms.
5.1 Evaluation Environment and Tasks
We wish to evaluate understanding of concepts under multiple contexts - generation and identiÔ¨Åcation.
To the best of our knowledge we are not aware of any existing datasets or environments that
simultaneously test both contexts for a wide range of concepts. For example, [ 17] tests understanding
via question answering, while [ 15] focuses on visual concepts. Thus to evaluate our method, we
introduce a new simulated environment and tasks which extend the work in [ 23]. The environment
is a two-dimensional scene consisting of a varying collection of entities, each processing position,
color, and shape properties. We wanted environment and tasks to be simple enough to facilitate ease
of analysis, yet complex enough to lead to formation of a variety of concepts. In this work we focus
5on position-based environment representation, but a pixel-based representation and generation would
be an exciting avenue for future work.
The task in this environment is, given Ndemonstration events that involve (we use N= 5) that
involve identical attention and state changes under different situations, perform analogous behavior
underNnovel test situations (by attending to analogous entities and performing analogous state
changes). Such behavior is not unique and these may be multiple possible solutions. Because our
energy model architecture in section 3 processes all entities independently, the number of entities
can vary between events. See Appendix for the description of events we consider in our dataset and
sites.google.com/site/energyconceptmodels for video results of our model learning on these events.
5.2 Understanding Concepts in Multiple Contexts
An important property of our model is ability to learn from and apply it in both generation and
identiÔ¨Åcation contexts. We qualitatively observe that the model performs sensible behavior in both
contexts. For example, we considered events with proximity relations "closest" and"farthest" and
found model able to both attend to entities that are closest or furthest to another entity, and to
move an entity to be closest or furthest to another entity as shown in Ô¨Ågure 4. There are multiple
admissible solutions which can be generated, as shown by the energy heatmap overlaid. We also wish
to understand several other properties of this formulation, which we discuss below.
Figure 4: Outcomes of generation (left) and iden-
tiÔ¨Åcation (right) for the concept of being farthest
to cross-shaped entity. Path in left image is the
optimization trajectory for the cross entity with the
energy heatmap is overlaid.
Transfer of learning between generation and identiÔ¨Åcation contexts: When our model trained
on both contexts it shares experience between contexts. Knowing how to act out a concept should
help in identifying it and vice versa - an effect observed in humans and other animals [ 1]. To
evaluate the efÔ¨Åcacy of transfer, we perform an experiment where we train the energy model only in
identiÔ¨Åcation context and test the model‚Äôs performance in generation context (and conversely and
second experiment where we train in generation context and test on identiÔ¨Åcation context). Since it is
difÔ¨Åcult to quantitatively evaluate generative models which have multiple admissible solutions, we
have collected a set of events that only involve the task of moving to an absolute location which have
unique answer that allows quantitative evaluation. The results of transfer between contexts on this
subset of events are reported in Ô¨Ågure 5.
We observe that even without explicitly being trained on the appropriate context, the networks
perform much better than baseline of two independently-trained networks, though not as effectively
as networks that were trained on both contexts. This transfer is advantageous because in many
situations demonstrations from only one type of context may be available, which our framework
would still be able to integrate.
0.0 2.5 5.0 7.5 10.0
inference iteration0.00.20.40.60.81.0state MSEGeneration
0.0 2.5 5.0 7.5 10.0
inference iteration0.00.10.20.30.40.50.60.7attention cross-entropyRecognition
Figure 5: Accuracy of transfer between contexts
for an absolute position concept. Red is error of
the model trained only in one context (generation
or identiÔ¨Åcation) evaluated on the opposite con-
text. Green is error of the model trained in both
contexts.
6Figure 6: Projected concept
codes for color events. redare
generation codes wxandblue
are attention codes wa.Sharing of concept codes across contexts: Another property of
our model is that codes wxandwafor identifying concepts are inter-
changeable and can be shared between generation and identiÔ¨Åcation
contexts. For example, either turning an entity red would or identi-
fying all red entities in the scene would ideally use the same concept
of"red" . We indeed observe that events which involve recognizing
entities of a particular color, the codes wamatch the codes wxfor
setting entities to that color (see Figure 6 for the PCA projection
of these codes). We Ô¨Ånd similar correlation in the other events as
well. Thus we see evidence that a concept code is reused across
contexts, similarly to how words in a language are used in multiple
contexts. This property presents exciting opportunities in applying our model to grounded language
understanding.
5.3 Optimization-Based Inference
Another important property of our model is that inference processes are based on iterative stochastic
optimization dynamics that build up output over time and may involve non-trivial feedback corrections.
In Ô¨Ågure 7 (left), we show examples of the optimization trajectories for generation of different shape
concepts. We see that the multi-step processes consist of a number of non-trivial feedback corrections
to achieve the appropriate joint arrangement of entities. On the other hand, a single-step processes
must achieve the arrangement through a single very precise step. While this can be adequate for
simple shapes such as a line, is it problematic for more complex shapes such as the square.
In optimization trajectories of attention vectors for identiÔ¨Åcation, we observe a mix of outcomes
- in some cases attention vector is settled on early in the optimization process, but in other cases
optimization involves non-trivial feedback corrections as shown in Ô¨Ågure 7 (top right). In optimization
of concept codes, we also observe that desired energy landscape forms only after multiple optimization
iterations as from in Ô¨Ågure 7 (bottom right).
Figure 7: Trajectories of our execution-time inference processes. Left: Generation trajectories for
shape concepts (given example shape) trained and executed with 1 optimization step and 20 steps.
Top Right: Examples of two attention vector optimization trajectories for identiÔ¨Åcation of a line
concept. Bottom Right: Examples of energy landscape as woptimization progresses.
Effect of a Relational Architecture We Ô¨Ånd that using a relational architecture in our model as
in equation 4 complements the optimization-based inference. We considered an alternative energy
function that independently operates over individual entities rather than pair of entities, such as
E(x;a;w) =f(P
t;i(ai)g(xt
i;w);w)2. We Ô¨Ånd that concepts that involve a single entity,
such as positioning or color concepts are able to be generated and identiÔ¨Åed without the use of relation
network architecture. However, for concepts that involve coordination of multiple entities such as
shape or temporal concepts we observe that not using relation network results in poor samples as
shown in "no RN" case of Ô¨Ågure 7.
7Effect of Training with LKLObjective We wish to understand whether it is necessary to explicitly
encourage inference process to produce good samples via LKLobjective in equation (8) as it involves
a computationally expensive back-propagation through the optimization procedure. Given enough
steps, stochastic gradient Langevin dynamics could in theory generate samples from the energy
model‚Äôs distribution without this explicit objective.
However, in our experiments we observe that training without LKLobjective, the gradient-based
inference process of equations in (3) is not able to produce good samples in a small number of steps.
Sample negative log-likelihoods are signiÔ¨Åcantly higher when training without LKLobjective. In
Ô¨Ågure 8 we see that while the energy network learns to discriminate between true example events
(plotted in green) and sampled and random events (plotted in red and black, respectively) as a result
of objectiveLML. However, the network is unable to produce sample events that match energy of
examples. On the other hand, the network trained with both objectives LMLandLKLis able to
generate samples that match the energies of examples while still being able to discriminate between
true example and random events.
Figure 8: Energy values from models trained with
and without KL objective. Green and positive
example events, redare sample events generated
by our run-time inference process, and black are
random events from the initial distribution.
5.4 Reuse of Concepts between Environments
When a concept is learned implicitly (as opposed to generated in a feed-forward manner by a generator
function or a policy), it allows the possibility to reuse the concept model under different environments
and actuation platforms, provided there can be a mapping between the representations of the two
environments.
To test generation of concepts in a different environment, we generated similar scenes in a three-
dimensional physically-based mujoco environment [ 33] where the actuation mechanism is joint
torques of a robotic arm rather than direct changes to environment state. To generate a concept, we
used model-predictive control [ 31] as the optimization mechanism and used energy function learned
in original environment as a cost for this optimization. Figure 9 shows results of reusing the concepts
to reenact behavior of original demonstration to move into a location between two blue entities. Note
that we manually deÔ¨Åned a correspondence between representations of two environments and do not
claim to tackle automatic transfer of representations - our aim is to show that learned energy functions
are robust to being used under different dynamics, actuation mechanism and control algorithm.
demonstration reenactment on robot 
Figure 9: Energy function of reach-
ing between blue objects learned from
demonstration in 2D particle environ-
ment reused in a 3D robot simulator un-
der a novel arrangement.
6 Conclusion
We believe that execution-time optimization plays a crucial role in acquisition and generalization
of knowledge, planning and abstract reasoning, and communication. In this preliminary work,
we proposed energy-based concept models as basic building blocks over which such optimization
procedures can fruitfully operate. In the current work we used a simple concept structure, but more
complex structure with multiple arguments or recursion would be interesting to investigate in the
future. It would also be interesting to test compositionality of concepts, which is very suited to our
model as compositions corresponds to the summation of the constituent energy functions.
8References
[1]S. Acharya and S. Shukla. Mirror neurons: enigma of the metaphysical modular brain. Journal
of natural science, biology, and medicine , 3(2):118, 2012.
[2]D. Belanger, B. Yang, and A. McCallum. End-to-end learning for structured prediction energy
networks. arXiv preprint arXiv:1703.05667 , 2017.
[3]Y . Bengio, A. Courville, and P. Vincent. Representation learning: A review and new perspectives.
IEEE transactions on pattern analysis and machine intelligence , 35(8):1798‚Äì1828, 2013.
[4]P. Dayan, G. E. Hinton, R. M. Neal, and R. S. Zemel. The helmholtz machine. Neural
computation , 7(5):889‚Äì904, 1995.
[5]K. Dvijotham and E. Todorov. Inverse optimal control with linearly-solvable mdps. In Proceed-
ings of the 27th International Conference on Machine Learning (ICML-10) , pages 335‚Äì342,
2010.
[6]C. Finn, P. Abbeel, and S. Levine. Model-agnostic meta-learning for fast adaptation of deep
networks. arXiv preprint arXiv:1703.03400 , 2017.
[7]C. Finn, P. Christiano, P. Abbeel, and S. Levine. A connection between generative adver-
sarial networks, inverse reinforcement learning, and energy-based models. arXiv preprint
arXiv:1611.03852 , 2016.
[8]C. Finn, S. Levine, and P. Abbeel. Guided cost learning: Deep inverse optimal control via policy
optimization. In International Conference on Machine Learning , pages 49‚Äì58, 2016.
[9]K. Friston. The free-energy principle: a uniÔ¨Åed brain theory? Nature Reviews Neuroscience ,
11(2):127‚Äì138, 2010.
[10] J. Fu, K. Luo, and S. Levine. Learning robust rewards with adversarial inverse reinforcement
learning. arXiv preprint arXiv:1710.11248 , 2017.
[11] I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. Courville, and
Y . Bengio. Generative adversarial nets. In Advances in neural information processing systems ,
pages 2672‚Äì2680, 2014.
[12] E. Grant, C. Finn, J. Peterson, J. Abbott, S. Levine, T. GrifÔ¨Åths, and T. Darrell. Concept
acquisition via meta-learning: Few-shot learning from positive examples. In Proceedings of the
NIPS 2017 Workshop on ‚ÄúCognitively Informed ArtiÔ¨Åcial Intelligence‚Äù , 2017.
[13] K. Gregor, I. Danihelka, A. Graves, D. J. Rezende, and D. Wierstra. Draw: A recurrent neural
network for image generation. arXiv preprint arXiv:1502.04623 , 2015.
[14] J. B. Hamrick, A. J. Ballard, R. Pascanu, O. Vinyals, N. Heess, and P. W. Battaglia. Metacontrol
for adaptive imagination-based optimization. arXiv preprint arXiv:1705.02670 , 2017.
[15] I. Higgins, N. Sonnerat, L. Matthey, A. Pal, C. P. Burgess, M. Botvinick, D. Hassabis, and
A. Lerchner. Scan: Learning abstract hierarchical compositional visual concepts. arXiv preprint
arXiv:1707.03389 , 2017.
[16] G. E. Hinton. Training products of experts by minimizing contrastive divergence. Training ,
14(8), 2006.
[17] J. Johnson, B. Hariharan, L. van der Maaten, L. Fei-Fei, C. L. Zitnick, and R. Girshick. Clevr:
A diagnostic dataset for compositional language and elementary visual reasoning. In Computer
Vision and Pattern Recognition (CVPR), 2017 IEEE Conference on , pages 1988‚Äì1997. IEEE,
2017.
[18] T. Kim and Y . Bengio. Deep directed generative models with energy-based probability estima-
tion. arXiv preprint arXiv:1606.03439 , 2016.
[19] D. P. Kingma and J. Ba. Adam: A method for stochastic optimization. arXiv preprint
arXiv:1412.6980 , 2014.
[20] D. P. Kingma and M. Welling. Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114 ,
2013.
[21] B. M. Lake, T. D. Ullman, J. B. Tenenbaum, and S. J. Gershman. Building machines that learn
and think like people. Behavioral and Brain Sciences , pages 1‚Äì101, 2016.
9[22] G. Lakoff and M. Johnson. The metaphorical structure of the human conceptual system.
Cognitive science , 4(2):195‚Äì208, 1980.
[23] R. Lowe, Y . Wu, A. Tamar, J. Harb, O. P. Abbeel, and I. Mordatch. Multi-agent actor-critic for
mixed cooperative-competitive environments. In Advances in Neural Information Processing
Systems , pages 6382‚Äì6393, 2017.
[24] C. Olah and S. Carter. Attention and augmented recurrent neural networks. Distill , 1(9):e1,
2016.
[25] E. Rosch, C. B. Mervis, W. D. Gray, D. M. Johnson, and P. Boyes-braem. Basic objects in
natural categories. COGNITIVE PSYCHOLOGY , 1976.
[26] R. Salakhutdinov and G. Hinton. Deep boltzmann machines. In ArtiÔ¨Åcial Intelligence and
Statistics , pages 448‚Äì455, 2009.
[27] A. Santoro, D. Raposo, D. G. Barrett, M. Malinowski, R. Pascanu, P. Battaglia, and T. Lillicrap.
A simple neural network module for relational reasoning. In Advances in neural information
processing systems , pages 4974‚Äì4983, 2017.
[28] D. Silver, J. Schrittwieser, K. Simonyan, I. Antonoglou, A. Huang, A. Guez, T. Hubert, L. Baker,
M. Lai, A. Bolton, et al. Mastering the game of go without human knowledge. Nature ,
550(7676):354, 2017.
[29] D. Silver, H. van Hasselt, M. Hessel, T. Schaul, A. Guez, T. Harley, G. Dulac-Arnold, D. Re-
ichert, N. Rabinowitz, A. Barreto, et al. The predictron: End-to-end learning and planning.
arXiv preprint arXiv:1612.08810 , 2016.
[30] A. Tamar, Y . Wu, G. Thomas, S. Levine, and P. Abbeel. Value iteration networks. In Advances
in Neural Information Processing Systems , pages 2154‚Äì2162, 2016.
[31] Y . Tassa, T. Erez, and E. Todorov. Synthesis and stabilization of complex behaviors through
online trajectory optimization. In Intelligent Robots and Systems (IROS), 2012 IEEE/RSJ
International Conference on , pages 4906‚Äì4913. IEEE, 2012.
[32] J. B. Tenenbaum. Bayesian modeling of human concept learning. In M. J. Kearns, S. A. Solla,
and D. A. Cohn, editors, Advances in Neural Information Processing Systems 11 , pages 59‚Äì68.
MIT Press, 1999.
[33] E. Todorov, T. Erez, and Y . Tassa. Mujoco: A physics engine for model-based control. In
Intelligent Robots and Systems (IROS), 2012 IEEE/RSJ International Conference on , pages
5026‚Äì5033. IEEE, 2012.
[34] T. Weber, S. Racani√®re, D. P. Reichert, L. Buesing, A. Guez, D. J. Rezende, A. P. Badia,
O. Vinyals, N. Heess, Y . Li, et al. Imagination-augmented agents for deep reinforcement
learning. arXiv preprint arXiv:1707.06203 , 2017.
[35] M. Welling and Y . W. Teh. Bayesian learning via stochastic gradient langevin dynamics. In
Proceedings of the 28th International Conference on Machine Learning (ICML-11) , pages
681‚Äì688, 2011.
[36] B. D. Ziebart, A. L. Maas, J. A. Bagnell, and A. K. Dey. Maximum entropy inverse reinforcement
learning. In AAAI , volume 8, pages 1433‚Äì1438. Chicago, IL, USA, 2008.
Appendix
Derivation of Joint Log-Likelihood Approximation
The derivation is similar to guided cost learning [ 8] and cost learning in linearly-solvable MDP [ 5]
formulations. Joint negative log-likelihood of observing tuple 
x0;x1;a
is logp 
x1;ajx0;w
= log 
p 
x1ja;wx
p 
ajx0;wa
(10)
= logexp
 E(x1;a;wx)	
R
~xexpf E(~x;a;wx)g logexp
 E(x0;a;wa)	
R
~aexpf E(x0;~a;wa)g(11)
Consider a more general form of the two individual terms above with non-negative function f
 logexpf f(x)gR
~xexpf f(~x)g=f(x) + log E~xqexpf f(~x)g
q(~x)
(12)
10The equality follows due to importance sampling under distribution q. There are a number of choices
for sampling distribution q, but a choice that simpliÔ¨Åes the above expression and we found to give
stable results in practice is q(X) =1
2I[X=x] +1
2I[X=~x]where ~xandis a distribution
that minimizes KL ((X)jjexpf f(X)g=Z).
In this case, sample-based approximation of equation (12) leads to
f(x) + log E~xqexpf f(~x)g
q(~x)
f(x) + log (expf f(x)g+ expf f(~x)g) (13)
= log (1 + expff(x) f(~x)g) = [f(x) f(~x)]+(14)
Using the above approximation in equation (11), gives the desired result  logp 
x1;ajx0;w

E(x1;a;wx) E(~x;a;wx)
++
E(x0;a;wa) E(x0;~a;wa)
+(15)
where ~xx(ja;wx);~aa 
jx0;wa
Environment Event Descriptions
We created a dataset containing a variety of events in our environment in order to evaluate learning
of a variety of concept in both generation and identiÔ¨Åcation contexts. This dataset is not meant to
be an exhaustive list of all possible concepts, but meant to represent a varied sampling of possible
interesting concepts. The events involve relations described below, which are either generated or
attended to:
Changing color of entities or attending to entities of a particular color.
Regional placement of entities in a particular spatial area - either a point, horizontal or
vertical line, circle, or corners of a square.
Placement relations of a one entity either north, south, east, west of another entity or between
two entities.
Shape relations between entities of either joining together, or forming a line, triangle, or
square shapes.
Proximity relations bring attention to the entity closest or furthest to another entity or to
bring that entity to be closest or furthest to the attended entity.
Quantity relations bring attention to any one, two, three, or more than three entities.
Temporal relations bring an one entity to another entity only after the other entity starts
moving.
Seesites.google.com/site/energyconceptmodels for video results of our model learning on these
events.
Experiment and Training Details
In all our experiments, fandgin the relation network in section 3 are multi-layer neural networks
with two hidden layers and 128 hidden units each. We use 5demonstration examples in Xdemoand
Xtrainfor each concept and use a batch size of 1024. We use K= 10 gradient descent steps for
concept inference and sampling. We trained our experiments for 10000 timesteps and used Adam
[19] optimizer with learning rate 10 3.
Additional Results
We provide quantitative results for the transfer of learning between generation and identiÔ¨Åcation
contexts described in Section 5.2.
Condition Generation Error Attention Error
Untrained Network 0.621 0.698
Trained on Generation 0.006 0.061
Trained on IdentiÔ¨Åcation 0.016 0.001
Trained on Both 0.007 0.001
11Algorithm Details
For completeness, we provide the algorithm of our method below.
Algorithm 1: Energy-based model learning from demonstration events
Initialize energy model parameters 
foreventsXtrainandXdemosampled from the same concept do
Randomly sample event 
x0;x1;a
fromXdemo
Initialize wxandwafrom unit Gaussian
forsampling iteration k= 1toKdo
Update samples wxandwavia stochastic gradient Langevin dynamics step:
wx() wx() +
2rwE(x0;a;wx()) +!k
wa() wa() +
2rwE(x1;a;wa()) +!k
end for
Randomly sample event 
x0;x1;a
fromXtrain
Initialize ~xtox0and initialize ~afrom unit Gaussian
forsampling iteration k= 1toKdo
Update samples ~xand~avia stochastic gradient Langevin dynamics step:
~x() ~x() +
2rxE(~x();a;wx()) +!k
~a() ~a() +
2raE(x0;~a();wa()) +!k
end for
Setxbe the result of applying gradient stopping operator on ~x(and similarly for a,wandE)
Formulate two losses operating over pandholding other function Ô¨Åxed:
LML() =
E(x1;a;wx()) E(x;a;wx())
++
E(x0;a;wa()) E(x0;a;wa())
+
LKL() =E(~x();a;wx) +E(x0;~a();wa)
Updatebased on gradientr(LML() +LKL())via Adam optimizer
end for
12